---
title: "Adult Longfin Smelt Presence/Absence BRT"
author: "Caroline Newell"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---
NOT ENOUGH DATA
NO GOOD

AgeClass  Year     N Count
   <chr>    <dbl> <int> <dbl>
 1 Age-0     2011   259    15
 2 Age-0     2012   254     8
 3 Age-0     2013   534   340
 4 Age-0     2014   317    56
 5 Age-0     2015   287     7
 6 Age-0     2016   289     2
 7 Age-0     2017   292     8
 8 Age-0     2018   276    16
 9 Age-0     2019   266     3
10 Age-0     2020   472   254
11 Age-0     2021   758   505
12 Age-0     2022   714   495
13 Age-0     2023   294    16
14 Age-1+    2011   257     8
15 Age-1+    2012   253     3
16 Age-1+    2013   227     2
17 Age-1+    2014   285     5
18 Age-1+    2015   287     1
19 Age-1+    2016   289     0
20 Age-1+    2017   290     0
21 Age-1+    2018   274     9
22 Age-1+    2019   265     0
23 Age-1+    2020   240     2
24 Age-1+    2021   289     3
25 Age-1+    2022   271    19
26 Age-1+    2023   292     4

### Loading libraries and data

```{r}
library(readr)
library(dismo)
library(caret)
library(here)
library(cowplot)
library(Hmisc)
library(tidyverse)

PresAbs<-read_csv("C:/Users/cnewe/OneDrive/Documents/Incubator/Code/FishForesightIncubator/Data/SMFS_Thesis_PresAbs_062524.csv")
```

# PresenceAbsence

## Step 1: Data visualization, Quality Check

Before modeling, we will ensure the data is up to snuff.

First things first, we need to get the data for the LongfinSmelt of interest we want to model.

```{r}
LongfinSmeltAdultData<-PresAbs %>% filter(gensp %in% "Spirinchus thaleichthys", AgeClass %in% "Age-1+") %>% dplyr::select(-...1, -...2)
LongfinSmeltAdultData<-as.data.frame(LongfinSmeltAdultData)
unique(LongfinSmeltAdultData$AgeClass)
```

Now lets check the dataset.

```{r}
glimpse(LongfinSmeltAdultData)
summary(LongfinSmeltAdultData)
NumSamples<-unique(LongfinSmeltAdultData$SampleRowID) #3505 sampling events.
```

Let's make a couple of plots for making predictions. First I need to make the data be just 1 row for each sampling event.

```{r}
LongfinSmeltAdultDataPA<-LongfinSmeltAdultData %>% dplyr::group_by(SampleRowID, WaterTemperature, DO, Secchi, Salinity, Year, Month, StationCode) %>% dplyr::summarize(Count=sum(Count)) %>% mutate(PresAbs = if_else(Count > 0, "present", "absent"), Binary=if_else(Count > 0, 1, 0))

LongfinSmeltAdultDataPA$PresAbs<-as.factor(LongfinSmeltAdultDataPA$PresAbs)

LongfinSmeltAdultDataPA$Year<-as.factor(LongfinSmeltAdultDataPA$Year)

LongfinSmeltAdultDataPA$Month<-as.factor(LongfinSmeltAdultDataPA$Month)

LongfinSmeltAdultDataPA$StationCode<-as.factor(LongfinSmeltAdultDataPA$StationCode)

LongfinSmeltAdultDataPA<-as.data.frame(LongfinSmeltAdultDataPA)

LongfinSmeltAdultDataPA %>% group_by(Year) %>% dplyr::summarize(N=n(), Count = sum(Count), BinarySum = sum(Binary), Probability=(BinarySum/N)*100) #Boom and bust years, not great for loo validation.

LongfinSmeltAdultDataPA %>% group_by(StationCode) %>% dplyr::summarize(N=n(), Count = sum(Count), BinarySum = sum(Binary), Probability=(BinarySum/N)*100) %>% print(n=24) #Some are heavily favored.

LongfinSmeltAdultDataPA %>% group_by(Month) %>% dplyr::summarize(N=n(), Count = sum(Count), BinarySum = sum(Binary), Probability=(BinarySum/N)*100) #Never in January and February

#Overall capture probability
(sum(LongfinSmeltAdultDataPA$Binary)/nrow(LongfinSmeltAdultDataPA))*100
```

6.22% probability of capturing yoy lfs.

```{r}
range(LongfinSmeltAdultDataPA$WaterTemperature)
mean(LongfinSmeltAdultDataPA$WaterTemperature)

range(LongfinSmeltAdultDataPA$DO)
mean(LongfinSmeltAdultDataPA$DO)

range(LongfinSmeltAdultDataPA$Salinity)
mean(LongfinSmeltAdultDataPA$Salinity)

range(LongfinSmeltAdultDataPA$Secchi)
mean(LongfinSmeltAdultDataPA$Secchi)

```



| Water Quality     | Mean      | Range           |
|-------------------|-----------|-----------------|
| Water temperature | 16.42 C   | 4.6, 27 C       |
| Dissolved oxygen  | 6.97 mg/L | 0.7, 13.74 mg/L |
| Salinity          | 4.69 psu  | 0, 15.8 psu     |
| Secchi            | 30.66 cm  | 7, 99 cm        |

```{r}
# I want to show presences vs. all samples.
#cdplot(y=LongfinSmeltAdultDataPA$PresAbs, x=LongfinSmeltAdultDataPA$WaterTemperature)

Plot_Water<-LongfinSmeltAdultDataPA %>% ggplot(aes(y=PresAbs, x=WaterTemperature)) + geom_violin(fill = "lightseagreen")+ stat_summary(fun.data="mean_sdl", fun.args=list(mult=1), geom= "pointrange", color="black") + theme_bw() + ylab("") + xlab("Water Temperature (C)") #+ facet_wrap(~Year)

Plot_DO<-LongfinSmeltAdultDataPA %>% ggplot(aes(y=PresAbs, x=DO)) + 
  geom_violin(fill = "lightseagreen")+ stat_summary(fun.data="mean_sdl", fun.args=list(mult=1), geom= "pointrange", color="black") + theme_bw()+ ylab("")+ xlab("Dissolved Oxygen (mg/L)") #+ facet_wrap(~Year)

Plot_Secchi<-LongfinSmeltAdultDataPA %>% ggplot(aes(y=PresAbs, x=Secchi)) + 
  geom_violin(fill = "lightseagreen")+ stat_summary(fun.data="mean_sdl", fun.args=list(mult=1), geom= "pointrange", color="black") + theme_bw()+ ylab("") + xlab("Secchi (cm)") #+ facet_wrap(~Year)

Plot_Salinity<-LongfinSmeltAdultDataPA %>% ggplot(aes(y=PresAbs, x=Salinity)) + geom_violin(fill = "lightseagreen")+ stat_summary(fun.data="mean_sdl", fun.args=list(mult=1), geom= "pointrange", color="black") + theme_bw()+ ylab("") + xlab("Salinity") #+ facet_wrap(~Year)

Plots<-plot_grid(Plot_Water, Plot_DO, Plot_Secchi, Plot_Salinity, ncol = 2, labels = "AUTO")

# now add the title
title <- ggdraw() + draw_label("Age-0 Longfin smelt presence/absence by water quality variables for SMFS 2011-2023", fontface = 'bold', x = 0, hjust = 0) +  theme(
    # add margin on the left of the drawing canvas,
    # so title is aligned with left edge of first plot
    plot.margin = margin(0, 0, 0, 7))

plot_grid(title, Plots, ncol = 1,
  # rel_heights values control vertical title margins
  rel_heights = c(0.1, 1))

SummTable <- LongfinSmeltAdultDataPA %>% 
  group_by(PresAbs) %>% #break down yearly summaries by including Year as a grouping variable. 
  dplyr::summarize(
    Mean_WT = mean(WaterTemperature, na.rm=TRUE),
    SD_WT = sd(WaterTemperature, na.rm=TRUE),
    MinWT=min(WaterTemperature, na.rm=TRUE),
    MaxWT=max(WaterTemperature, na.rm=TRUE),
    Mean_DO = mean(DO, na.rm=TRUE),
    SD_DO = sd(DO, na.rm=TRUE),
    MinDO=min(DO, na.rm=TRUE),
    MaxDO=max(DO, na.rm=TRUE),
    Mean_Secchi = mean(Secchi, na.rm=TRUE),
    SD_Secchi = sd(Secchi, na.rm=TRUE),
    MinSecchi=min(Secchi, na.rm=TRUE),
    MaxSecchi=max(Secchi, na.rm=TRUE),
    Mean_Salinity = mean(Salinity, na.rm=TRUE),
    SD_Salinity = sd(Salinity, na.rm=TRUE),
    MinSal=min(Salinity, na.rm=TRUE),
    MaxSal=max(Salinity, na.rm=TRUE)
  ) 

print(SummTable)
write.csv(SummTable, here("data", "LongfinSmeltYOY_SummTable.csv"))

#Seasonality
LongfinSmeltAdultDataPA %>% dplyr::summarize(TotalPresence=sum(Binary, na.rm=TRUE), sd_binary=sd(Binary, na.rm=TRUE), n=n(), PercentageOfPresence=100*(TotalPresence/n)) #Total presence = 1971 of 5471. 36.03% presence of samples.

LongfinSmeltAdultDataPA %>% group_by(Month) %>% dplyr::summarize(TotalPresence=sum(Binary), sd_binary=sd(Binary), n=n(), PercentageOfPresence=100*(TotalPresence/n)) %>% ggplot(aes(x=Month, y=TotalPresence)) +geom_col()+geom_linerange(aes(ymin=TotalPresence-sd_binary, ymax=TotalPresence+sd_binary))+theme_bw(base_size = 26)+ylab("Trawls that catch yoy longfin smelt") +xlab("Month (summed 2011-2023)") #+ theme(axis.text.x = element_text(angle = 45, hjust=1))
LongfinSmeltAdultDataPA %>% group_by(StationCode) %>% dplyr::summarize(TotalPresence=sum(Binary), sd_binary=sd(Binary), n=n(), PercentageOfPresence=100*(TotalPresence/n)) %>% ggplot(aes(x=StationCode, y=PercentageOfPresence)) +geom_col()+theme_bw(base_size = 26)+ylab("% of trawls that catch yoy longfin smelt") +xlab("Station Code") + theme(axis.text.x = element_text(angle = 45, hjust=1))
```

Most restricted presence compared to absence is dissolved oxygen. High secchi depth (clear water) also lacks presence above 75 cm.

Do the most influential?

## Step 2: Use gbm() from dismo to run model and create outputs

Thanks Nima and Elith! Follow <https://bradleyboehmke.github.io/HOML/gbm.html> for tuning strategy?

### Setting hyperparameters

```{r}

str(LongfinSmeltAdultDataPA)

 set.seed(124) # for reproducibility 
#gbm.step wants bernoulli response {0, 1} 
Complexity<-4
LearningRate<-0.001
Bag<-0.6

```

```{r}
system.time( brt1 <- dismo::gbm.step(data=LongfinSmeltAdultDataPA, 
                         gbm.x= c(2,3,4,5), # environmental variables. 2 = Water Temperature, 5 = salinity, 3 = DO, 4 = Secchi
                         gbm.y= 11, # Binary response variable
                         family = "bernoulli", # for counts this would be "poisson"
                         tree.complexity = Complexity, # complexity of the interactions that the model will fit. 5-way interaction since these may all interact with one another? Typical values range from a depth of 3â€“8 but it is not uncommon to see a tree depth of 1 (J. Friedman, Hastie, and Tibshirani 2001). Smaller depth trees such as decision stumps are computationally efficient (but require more trees); however, higher depth trees allow the algorithm to capture unique interactions but also increase the risk of over-fitting. Note that larger  n  or  p training data sets are more tolerable to deeper trees.
                         learning.rate = LearningRate,  # optimized to end up with >1000 trees. Smaller values make the model robust to the specific characteristics of each individual tree, thus allowing it to generalize well. Smaller values also make it easier to stop prior to overfitting; however, they increase the risk of not reaching the optimum with a fixed number of trees and are more computationally demanding
                         bag.fraction = Bag # default for Elith, amount of input data used each time. the fraction of the training set observations randomly selected to propose the next tree in the expansion. This introduces randomnesses into the model fit. If bag.fraction < 1 then running the same model twice will result in similar but different fits. gbm uses the R random number generator so set.seed can ensure that the model can be reconstructed. 0.5 is ridgeway's preference.
                         ))

# make sure to save the model!
summary(brt1)

mean(brt1$residuals^2) #mean residual deviance 0.309
#brt1$
names(brt1) #tells us the components of output

# To pull out one component of the list, use a number (angaus.tc5.lr01[[29]]) or name (angaus.tc5.lr01$cv.statistics); but be careful - some are as big as the dataset! e.g. there will be 1000 fitted values - find this by typing length(angaus.tc5.lr01$fitted)

 # reponse curves
dismo::gbm.plot(brt1, n.plots = 4, write.title= F, rug = T, smooth = TRUE, plot.layout=c(2,2), common.scale = T, y.label = "Fitted Value") #Makes the partial dependence plots.

gbm::plot.gbm(brt1, n.plots=4, return.grid=TRUE)

dismo::gbm.plot.fits(brt1)
#I assume these wtm's are weighted means and are the means used when calculating partial dependence? So each dot is a prediction made from a single tree?


# This code assesses the extent to which pairwise interactions exist in the data.

find.int <- gbm.interactions(brt1)
find.int#Salinity and DO, Salinity and Water Temp.
brt1$self.statistics$correlation[[1]] #The relevant set of evaluation statistics, calculated on the fitted values - i.e. this is only interesting in so far as it demonstrates "evaluation" (i.e. t) on the training data. It should NOT be reported as the model predictive performance.
# The returned object, here named test.int, is a list. The first 2 components summarise the results, first as a ranked list of the 5 most important pairwise interactions, and the second tabulating all pairwise interactions. The variable index numbers in $rank.list can be used for plotting.

brt1$cv.statistics #These are the most appropriate evaluation statistics. We calculate each statistic within each fold (at the identifed optimal number of trees that is calculated on the mean change in predictive deviance over all folds), then present here the mean and standard error of those fold-based statistics.

# You can plot pairwise interactions like this:
par(mfrow=c(1,2))
gbm.perspec(brt1,2, 4) #3D PLOT of Water Temp and Salinity
gbm.perspec(brt1,1, 4) #salinity and DO
gbm.perspec(brt1,1, 2)
#5 is tow duration. 4 is secchi. 1 is water temp.2 is salinity. 3 is DO
# save the model
saveRDS(brt1, here("data", "LongfinSmelt_brt_gbm_step.rds"))


#predicted<-predict(object=brt1, )
```

For the final model (lr = , tc = , bag fraction = )

Interaction report:


## Validation

Below are 2 validation schemes that we typically use to assess how well the model is predicting. The first is a K-fold cross-validation where the data is split in k number of equal sections (i.e. folds). A model is the trained on one fold and then its predicts to the rest of the folds. It then iterates this process through all the folds. Most studies do 10 folds as this has shown to be a good number. Too low or too high has shown to potentially bias / cause variability in results.

Performance metrics that are calculated are deviance explained, AUC, and TSS. Deviance explained is a metric for how much variance did our model explain (you can think of is as R squared) and AUC and TSS are assessing predictive skill. Since you are using abundance data you may need to change that to RMSE or MAE (Iâ€™d suggest taking a look at the Metrics package for that)

NOTE: whether you are using gbm.fixed or gbm.step to fit your BRTS, you will have to make a slight change to this function below. Iâ€™ve commented lines out since I made the model above using gbm.fixed but if used gbm.step I would used the code on those lines instead.

```{r}
#k fold cross validation function

eval_kfold_brt <- function(dataInput, gbm.x, gbm.y, learning.rate = LearningRate, k_folds = 10, tree.complexity = Complexity, bag.fraction = Bag){
  dataInput$Kset <- dismo::kfold(dataInput, k_folds) #randomly allocate k groups
  Evaluations_kfold_BRT <- as.data.frame(matrix(data=0,nrow=5,ncol=4)) 
  colnames(Evaluations_kfold_BRT) <- c("k","Deviance","AUC","TSS")
  counter=1
  for (k in 1:k_folds){
    print(k)
    train <- dataInput[dataInput$Kset!=k,]
    test <- dataInput[dataInput$Kset==k,]
    
     brt.k <- dismo::gbm.step(data=train, gbm.x= gbm.x, 
                             gbm.y = gbm.y, 
                              family="bernoulli", 
                             tree.complexity = tree.complexity,
                             learning.rate = learning.rate, 
                             bag.fraction = bag.fraction)
    
    preds <- gbm::predict.gbm(brt.k, test,
                              n.trees=brt.k$gbm.call$best.trees, 
                              type="response")
    
    dev_eval3<-function(x){
      null <- x$self.statistics$mean.null #use with gbm.step
      res <- x$self.statistics$mean.resid #use with gbm.step
      dev=((null - res)/null)*100
      return(dev)
    }
    dev<-dev_eval3(brt.k)
    d <- cbind(test[gbm.y], preds)
    pres <- as.numeric(d[d[,1]==1,2])
    abs <- as.numeric(d[d[,1]==0,2])
    e <- dismo::evaluate(p=pres, a=abs)
    Evaluations_kfold_BRT[counter,1] <- k
    Evaluations_kfold_BRT[counter,2] <- dev
    Evaluations_kfold_BRT[counter,3] <- e@auc
    Evaluations_kfold_BRT[counter,4] <- max(e@TPR + e@TNR-1)
    counter=counter+1 
  }
  return(Evaluations_kfold_BRT)
}
  
  
brt_SDM_k <- eval_kfold_brt(dataInput = LongfinSmeltAdultDataPA,
                        gbm.x = c(2,3,4,5),
                        gbm.y=11, learning.rate = LearningRate,
                        bag.fraction = Bag, tree.complexity = Complexity,
                        k_folds = 10)
brt_SDM_k
```

The other validation scheme that we do is a Leave one [year] out cross-validation. Just like 5 folds but now were trained the model on all the data but one year. And then we predict to that one year that was not included. This give us a sense out how well can we predict year by year as there may be some environmental variability over time.

NOTE: Same as above of changing the code whether you are using gbm.fixed or gbm.step

```{r}
#leave one year out function

eval_loo_brt <- function(pres, abs, gbm.x, gbm.y, learning.rate = LearningRate, tree.complexity = Complexity, bag.fraction = Bag){
  
  pres$year <- pres$Year
  abs$year <- abs$Year
  
  ## setup output df
  Evaluations_LOO_BRT <- as.data.frame(matrix(data = 0, nrow = 1, ncol = 5))
  colnames(Evaluations_LOO_BRT) <- c("k","Deviance","AUC","TSS","n_pres")
  counter=1
  
  u_years <- unique(pres$year)
  for (y in u_years){
    
    print(paste('Running ', which(u_years == y), ' of ', length(u_years), sep=''), sep='')
    
    pres_train <- pres[which(pres$year != y),]
    ## absences are sampled from the full input absence df
    abs_train <- abs[sample(which(abs$year != y), size = nrow(pres_train), replace=F),]
    train <- rbind(pres_train, abs_train)
    
    pres_test <- pres[which(pres$year == y),]
    abs_test <- abs[sample(which(abs$year == y), size = nrow(pres_test), replace=F),]
    test <- rbind(pres_test, abs_test)
    
    
     brt.loo <- dismo::gbm.step(data=train, gbm.x= gbm.x, 
                                gbm.y = gbm.y, 
                                family="bernoulli", 
                                tree.complexity = tree.complexity,
                               learning.rate = learning.rate, 
                               bag.fraction = bag.fraction)
    
    ## make predictions for eval
    preds <- gbm::predict.gbm(brt.loo, test,
                              n.trees=brt.loo$gbm.call$best.trees, 
                              type="response")
    
    dev_eval3<-function(x){
      null <- x$self.statistics$mean.null #use with gbm.step
      res <- x$self.statistics$mean.resid #use with gbm.step
      dev=((null - res)/null)*100
      return(dev)
    }
    dev<-dev_eval3(brt.loo)
    d <- cbind(test[,gbm.y], preds)
    pres_y <- as.numeric(d[d[,1] == 1,2])
    abs_y <- as.numeric(d[d[,1] == 0,2])
    e <- dismo::evaluate(p = pres_y, a = abs_y)
    
    Evaluations_LOO_BRT[counter,1] <- y
    Evaluations_LOO_BRT[counter,2] <- dev
    Evaluations_LOO_BRT[counter,3] <- e@auc
    Evaluations_LOO_BRT[counter,4] <- max(e@TPR + e@TNR-1)
    Evaluations_LOO_BRT[counter,5] <- length(which(train[,gbm.y] == 1))
    
    counter=counter+1 
  }
  return(Evaluations_LOO_BRT)
}

brt_SDM_loo <- eval_loo_brt(pres = LongfinSmeltAdultDataPA[which(LongfinSmeltAdultDataPA$Binary == 1),],
                        abs = LongfinSmeltAdultDataPA[which(LongfinSmeltAdultDataPA$Binary == 0),],
                        gbm.x = c(2,3,4,5),
                        gbm.y=11, learning.rate = LearningRate,
                        bag.fraction = Bag, tree.complexity = Complexity)
brt_SDM_loo

#combining the model output, and both validation results into a list to save
eval <- list(brt = brt1, brt_k = brt_SDM_k, brt_loo = brt_SDM_loo)

eval
#now save it

saveRDS(eval, here("data","YOYLongfinSmelt_brt_SDM_eval_gbm_step.rds"))
```

learning.rate = 0.008, bag.fraction = 0.6, tree.complexity = 4:

A gradient boosted model with bernoulli loss function.
1100 iterations were performed.
There were 4 predictors of which 4 had non-zero influence.

$brt_k
    k Deviance       AUC       TSS
1   1 36.06116 0.8189071 0.5722643
2   2 32.38994 0.7789322 0.4411255
3   3 33.57384 0.7111604 0.3543120
4   4 40.16386 0.8205538 0.5600000
5   5 34.99054 0.8659719 0.6342452
6   6 30.97233 0.8972694 0.7323701
7   7 33.75016 0.6777572 0.3044804
8   8 34.82977 0.8483925 0.5753880
9   9 35.82083 0.7711740 0.4863715
10 10 33.02876 0.8463463 0.6606607

$brt_loo
      k Deviance       AUC       TSS n_pres
1  2013 34.88317 0.6933594 0.3125000    186
2  2021 38.64269 0.8449074 0.5555556    182
3  2017 37.21238 0.5555556 0.3333333    212
4  2014 41.46111 0.6735537 0.4090909    196
5  2023 36.23444 0.7291667 0.5833333    206
6  2022 32.79467 0.8595062 0.6222222    173
7  2015 37.31258 0.7551020 0.4285714    211
8  2011 41.83404 0.5207101 0.2307692    205
9  2020 31.88135 0.7913223 0.5909091    196
10 2012 40.74887 0.6530612 0.5714286    211
11 2018 37.87022 0.7986111 0.5833333    206
12 2019 34.98621 0.5000000 0.5000000    216
13 2016 39.04901 0.7500000 0.5000000    216
## Analyzing Response Curves & Variable Importance

Look at Nima's code for pretty plots: <https://github.com/nfarchadi/heatwave_impacts_on_fisheries/blob/main/scripts/4_plots/FS3_FS4_response_relimport_plots.R>

```{r}
# Fig. S3. The relative importance of drivers in distribution models
# Fig. S4. Response curves of each environmental variable from distribution models


###----response plots----####

brt_LongfinSmelt <- here("data","LongfinSmelt_brt_SDM_eval_gbm_step.rds") %>% readRDS()


# get the matrix out of the `plot.gbm`
var<-brt_LongfinSmelt$brt$var.names
response_data<-data.frame()

for (i in 1:length(var)){
response_plot_data <- gbm::plot.gbm(brt_LongfinSmelt$brt,
                                 i.var = var[i],
                                 return.grid = TRUE)

response_plot_data<-response_plot_data %>% gather("variable","x",-y)

response_data<-rbind(response_data, response_plot_data)

}

#Get it on the same scale as elith
#response_data$y <- response_data[,2] - mean(response_data[,2])
#response_data$y<-1/(1+exp(-response_data$y))

#response_data$y<-scale(response_data$y, scale = FALSE)

#Add a smoothed line to an active plot
#loess(y ~ x, span = 0.3)

response_data %>%
  ggplot() + 
  geom_line(aes(x=x, y=y), color = "lightseagreen", size =1) + 
  facet_wrap(~variable, scales = "free", nrow = 5) +
  labs(x = "Variable Values",
       y = "Marginal Effect")+
  theme_bw() + 
  theme(panel.spacing = unit(.30, "lines"),
        strip.text = element_text(size=10),
        strip.background = element_blank(),
        strip.text.x = element_text(margin = margin(0,0,.05,0, "cm")))
  
ggsave(here("Plots","LongfinSmelt_response_plots.png"),
       width = 7, height = 6, units = "in", dpi = 300)
#ggsave(here("Plots","LongfinSmelt_response_plots.svg"),
#       width = 7, height = 6, units = "in", dpi = 300)

###----variable contribution----####
rel.inf<-data.frame(Variable = brt_LongfinSmelt$brt$contributions$var,
                        rel.inf=brt_LongfinSmelt$brt$contributions$rel.inf)# %>% 



rel.inf %>% 
  ggplot()+
  geom_bar(aes(x = reorder(Variable, -rel.inf),y=rel.inf), fill = "lightseagreen",
           stat="identity", position=position_dodge())+
  theme_bw() +
  labs(x = "Environmental Variable",
       y = "Relative Importance (%)")+
  theme(axis.text.x = element_text(angle = 45,hjust=1))

ggsave(here("Plots","LongfinSmelt_relative_importance.png"),
       width = 7, height = 6, units = "in", dpi = 300)
#ggsave(here("Plots","FS3_relative_importance.svg"),
#       width = 7, height = 6, units = "in", dpi = 300)
```

When looking at partial dependence plots, the y-axis represents the marginal impact of the independent variable to the dependent variable. If at 0, then there is 0 impact...

# NOTES

-   If number of trees below 1k, need to lower learning rate.
-   There may be a difference in the caret output and gbm output (5%). To avoid this can use the default grid to optimize parameters and use predict to have the same results... Or don't worry about it.
